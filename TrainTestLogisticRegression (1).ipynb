{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train=pd.read_csv('C:\\\\Users\\\\jalan\\\\Desktop\\\\CapStone Retrieved\\\\TrainTestMethod\\\\Traincorpwithoutsidecorpus.csv')\n",
    "test=pd.read_csv('C:\\\\Users\\\\jalan\\\\Desktop\\\\CapStone Retrieved\\\\TrainTestMethod\\\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9318,), (9318,), (2057,), (2057,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.stemmedjoin\n",
    "y_train = train.labels\n",
    "X_test = test.stemmedjoin\n",
    "y_test = test.labels\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     6582\n",
       "positive    1728\n",
       "negative    1008\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=None, max_features=200000, ngram_range=(1, 2))\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9318, 55549)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pd=pd.DataFrame(X_train_dtm.todense(),columns=vect.get_feature_names())\n",
    "tfidf_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2057x55549 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21404 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#over sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=777)\n",
    "X_ROS, y_ROS = ros.fit_sample(X_train_dtm, y_train)\n",
    "#under sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=777)\n",
    "X_RUS, y_RUS = rus.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 116 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.00      0.00      0.00       111\n",
      "    neutral       0.80      1.00      0.89      1649\n",
      "   positive       1.00      0.01      0.01       297\n",
      "\n",
      "avg / total       0.79      0.80      0.72      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "%time NB.fit(X_train_dtm, y_train)\n",
    "y_pred_class_NB = NB.predict(X_test_dtm)\n",
    "# calculate precision and recall\n",
    "print(classification_report(y_test, y_pred_class_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 67.8 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.18      0.32      0.23       111\n",
      "    neutral       0.88      0.71      0.79      1649\n",
      "   positive       0.32      0.59      0.42       297\n",
      "\n",
      "avg / total       0.76      0.67      0.70      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time NB.fit(X_ROS, y_ROS)\n",
    "y_pred_class_NBROS = NB.predict(X_test_dtm)\n",
    "# calculate precision and recall\n",
    "print(classification_report(y_test, y_pred_class_NBROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.9 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.18      0.41      0.25       111\n",
      "    neutral       0.89      0.59      0.71      1649\n",
      "   positive       0.26      0.62      0.37       297\n",
      "\n",
      "avg / total       0.76      0.59      0.64      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time NB.fit(X_RUS, y_RUS)\n",
    "y_pred_class_NBRUS = NB.predict(X_test_dtm)\n",
    "# calculate precision and recall\n",
    "print(classification_report(y_test, y_pred_class_NBRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial',solver='lbfgs',C=15)#15 seems to be around optimal value. Regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.85 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.27      0.14      0.18       111\n",
      "    neutral       0.84      0.92      0.88      1649\n",
      "   positive       0.47      0.31      0.37       297\n",
      "\n",
      "avg / total       0.76      0.79      0.77      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time lr.fit(X_train_dtm, y_train)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_lr = lr.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.81 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.24      0.21      0.22       111\n",
      "    neutral       0.87      0.86      0.87      1649\n",
      "   positive       0.43      0.46      0.45       297\n",
      "\n",
      "avg / total       0.77      0.77      0.77      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time lr.fit(X_ROS, y_ROS)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_lrROS = lr.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_lrROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.67 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.16      0.44      0.24       111\n",
      "    neutral       0.89      0.63      0.74      1649\n",
      "   positive       0.29      0.60      0.39       297\n",
      "\n",
      "avg / total       0.77      0.61      0.66      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time lr.fit(X_RUS, y_RUS)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_lrRUS = lr.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_lrRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 186 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.26      0.06      0.10       111\n",
      "    neutral       0.83      0.95      0.89      1649\n",
      "   positive       0.47      0.21      0.29       297\n",
      "\n",
      "avg / total       0.75      0.80      0.76      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "%time sgd_clf.fit(X_train_dtm, y_train)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_sgd = sgd_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.28      0.29      0.28       111\n",
      "    neutral       0.88      0.83      0.85      1649\n",
      "   positive       0.39      0.51      0.44       297\n",
      "\n",
      "avg / total       0.77      0.75      0.76      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_ROS, y_ROS)\n",
    "y_pred_class_sgdROS = sgd_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_sgdROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.15      0.47      0.23       111\n",
      "    neutral       0.88      0.61      0.72      1649\n",
      "   positive       0.28      0.55      0.37       297\n",
      "\n",
      "avg / total       0.76      0.59      0.64      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(X_RUS, y_RUS)\n",
    "y_pred_class_sgdRUS = sgd_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_sgdRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 788 ms\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.20      0.01      0.02       111\n",
      "    neutral       0.82      0.97      0.89      1649\n",
      "   positive       0.48      0.15      0.23       297\n",
      "\n",
      "avg / total       0.74      0.80      0.75      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(min_samples_split=50,min_samples_leaf=100)\n",
    "%time tree_clf.fit(X_train_dtm, y_train)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_tree = tree_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.10      0.28      0.14       111\n",
      "    neutral       0.87      0.61      0.72      1649\n",
      "   positive       0.25      0.48      0.33       297\n",
      "\n",
      "avg / total       0.74      0.58      0.63      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_clf.fit(X_ROS, y_ROS)\n",
    "y_pred_class_treeROS = tree_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_treeROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.06      0.40      0.11       111\n",
      "    neutral       0.83      0.44      0.57      1649\n",
      "   positive       0.24      0.37      0.29       297\n",
      "\n",
      "avg / total       0.70      0.43      0.51      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tree_clf = DecisionTreeClassifier(max_depth=175,min_samples_split=100)\n",
    "tree_clf.fit(X_RUS, y_RUS)\n",
    "y_pred_class_treeRUS = tree_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_treeRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.00      0.00      0.00       111\n",
      "    neutral       0.80      1.00      0.89      1649\n",
      "   positive       0.00      0.00      0.00       297\n",
      "\n",
      "avg / total       0.64      0.80      0.71      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train_dtm, y_train)\n",
    "y_pred_bagg = bag_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_bagg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.07      0.39      0.12       111\n",
      "    neutral       0.83      0.62      0.71      1649\n",
      "   positive       0.38      0.27      0.32       297\n",
      "\n",
      "avg / total       0.72      0.56      0.62      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_ROS, y_ROS)\n",
    "y_pred_baggROS = bag_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_baggROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.07      0.39      0.12       111\n",
      "    neutral       0.82      0.62      0.70      1649\n",
      "   positive       0.35      0.25      0.29       297\n",
      "\n",
      "avg / total       0.71      0.55      0.61      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_RUS, y_RUS)\n",
    "y_pred_baggRUS = bag_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_baggRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 49s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.25      0.04      0.06       111\n",
      "    neutral       0.82      0.97      0.89      1649\n",
      "   positive       0.49      0.13      0.20       297\n",
      "\n",
      "avg / total       0.74      0.80      0.74      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=500,  n_jobs=-1)\n",
    "%time RF.fit(X_train_dtm, y_train)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_RFtree = RF.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_RFtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.24      0.06      0.10       111\n",
      "    neutral       0.82      0.95      0.88      1649\n",
      "   positive       0.42      0.19      0.26       297\n",
      "\n",
      "avg / total       0.73      0.79      0.75      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF.fit(X_ROS, y_ROS)\n",
    "y_pred_class_RFtreeROS = RF.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_RFtreeROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.14      0.25      0.18       111\n",
      "    neutral       0.86      0.73      0.79      1649\n",
      "   positive       0.29      0.43      0.35       297\n",
      "\n",
      "avg / total       0.74      0.67      0.69      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF.fit(X_RUS, y_RUS)\n",
    "y_pred_class_RFtreeRUS = RF.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_RFtreeRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTreesClassifier (Extremely Random Random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ETC = ExtraTreesClassifier(n_estimators=1000,  n_jobs=-1)\n",
    "%time ETC.fit(X_train_dtm, y_train)\n",
    "y_pred_class_ETCtree = ETC.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_ETCtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ETCros.fit(X_ROS, y_ROS)\n",
    "y_pred_class_ETCtreeROS = ETCros.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_ETCtreeROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.20      0.37      0.26       111\n",
      "    neutral       0.87      0.77      0.81      1649\n",
      "   positive       0.33      0.45      0.38       297\n",
      "\n",
      "avg / total       0.75      0.70      0.72      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ETCrus.fit(X_RUS, y_RUS)\n",
    "y_pred_class_ETCtreeRUS = ETCrus.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_ETCtreeRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.5 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.23      0.05      0.09       111\n",
      "    neutral       0.83      0.96      0.89      1649\n",
      "   positive       0.52      0.20      0.29       297\n",
      "\n",
      "avg / total       0.75      0.80      0.76      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#svm = svm.SVC(gamma=1)\n",
    "svm = svm.SVC(kernel=\"poly\", degree=1,gamma=1, coef0=1)\n",
    "%time svm.fit(X_train_dtm, y_train)\n",
    "# make class predictions for X_test_dtm - Test\n",
    "y_pred_class_svm = svm.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.21      0.14      0.17       111\n",
      "    neutral       0.86      0.87      0.87      1649\n",
      "   positive       0.43      0.46      0.45       297\n",
      "\n",
      "avg / total       0.77      0.77      0.77      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_ROS, y_ROS)\n",
    "y_pred_class_svmROS = svm.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_svmROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.17      0.41      0.24       111\n",
      "    neutral       0.88      0.67      0.76      1649\n",
      "   positive       0.30      0.55      0.39       297\n",
      "\n",
      "avg / total       0.76      0.64      0.68      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_RUS, y_RUS)\n",
    "y_pred_class_svmRUS = svm.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_svmRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.13      0.22      0.16       111\n",
      "    neutral       0.85      0.77      0.81      1649\n",
      "   positive       0.30      0.38      0.34       297\n",
      "\n",
      "avg / total       0.73      0.68      0.70      2057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=5000,algorithm=\"SAMME.R\", learning_rate=0.01)\n",
    "ada_clf.fit(X_RUS, y_RUS)\n",
    "y_pred_class_adaRUS = ada_clf.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_adaRUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Results=pd.DataFrame(np.zeros((15,3)),columns=['negative','neutral','positive']) # Creting empty dataframe \n",
    "#Results['Technique']=0\n",
    "negative=(classification_report(y_test, y_pred_class_NBRUS)[82:86],classification_report(y_test, y_pred_class_lrRUS)[82:86],\\\n",
    " classification_report(y_test, y_pred_class_sgdRUS)[82:86], classification_report(y_test, y_pred_class_treeRUS)[82:86],\\\n",
    " classification_report(y_test, y_pred_baggRUS)[82:86], classification_report(y_test, y_pred_class_RFtreeRUS)[82:86],\\\n",
    " classification_report(y_test, y_pred_class_ETCtreeRUS)[82:86], classification_report(y_test, y_pred_class_svmRUS)[82:86],\\\n",
    " classification_report(y_test, y_pred_class_adaRUS)[82:86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutral=(classification_report(y_test, y_pred_class_NBRUS)[135:139],classification_report(y_test, y_pred_class_lrRUS)[135:139],\\\n",
    " classification_report(y_test, y_pred_class_sgdRUS)[135:139], classification_report(y_test, y_pred_class_treeRUS)[135:139],\\\n",
    " classification_report(y_test, y_pred_baggRUS)[135:139], classification_report(y_test, y_pred_class_RFtreeRUS)[135:139],\\\n",
    " classification_report(y_test, y_pred_class_ETCtreeRUS)[135:139], classification_report(y_test, y_pred_class_svmRUS)[135:139],\\\n",
    " classification_report(y_test, y_pred_class_adaRUS)[135:139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive=(classification_report(y_test, y_pred_class_NBRUS)[188:192],classification_report(y_test, y_pred_class_lrRUS)[188:192],\\\n",
    " classification_report(y_test, y_pred_class_sgdRUS)[188:192], classification_report(y_test, y_pred_class_treeRUS)[188:192],\\\n",
    " classification_report(y_test, y_pred_baggRUS)[188:192], classification_report(y_test, y_pred_class_RFtreeRUS)[188:192],\\\n",
    " classification_report(y_test, y_pred_class_ETCtreeRUS)[188:192], classification_report(y_test, y_pred_class_svmRUS)[188:192],\\\n",
    " classification_report(y_test, y_pred_class_adaRUS)[188:192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Binomial</th>\n",
       "      <th>Log Reg</th>\n",
       "      <th>Stochastic Gradient</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Bagging</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <th>Support Vector Classifiers</th>\n",
       "      <th>Ada Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Negative Binomial Log Reg Stochastic Gradient Decision Tree Bagging  \\\n",
       "negative              0.41    0.44                0.47          0.40    0.39   \n",
       "neutral               0.59    0.63                0.61          0.44    0.62   \n",
       "positive              0.62    0.60                0.55          0.37    0.25   \n",
       "\n",
       "         Random Forest ExtraTreesClassifier Support Vector Classifiers  \\\n",
       "negative          0.25                 0.37                       0.41   \n",
       "neutral           0.73                 0.77                       0.67   \n",
       "positive          0.43                 0.45                       0.55   \n",
       "\n",
       "         Ada Boost  \n",
       "negative      0.22  \n",
       "neutral       0.77  \n",
       "positive      0.38  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = pd.DataFrame([negative,neutral,positive],columns=['Negative Binomial','Log Reg','Stochastic Gradient','Decision Tree', 'Bagging', 'Random Forest','ExtraTreesClassifier',\\\n",
    "          'Support Vector Classifiers', 'Ada Boost'])\n",
    "Results.index=['negative','neutral','positive',]\n",
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.24      0.22      0.23       111\n",
      "    neutral       0.87      0.85      0.86      1649\n",
      "   positive       0.42      0.48      0.45       297\n",
      "\n",
      "avg / total       0.77      0.76      0.77      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eAlg = VotingClassifier(estimators=[('NB',NB),('LR',lr),('SGD',sgd_clf),('DT',tree_clf),('svc',svm)],\n",
    "                        voting='hard')#,weights=[2,2,1,2,1])\n",
    "eAlg.fit(X_ROS, y_ROS)\n",
    "y_pred_class_vsROS = eAlg.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_vsROS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.15      0.47      0.22       111\n",
      "    neutral       0.88      0.63      0.73      1649\n",
      "   positive       0.31      0.56      0.40       297\n",
      "\n",
      "avg / total       0.76      0.61      0.66      2057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "eAlg = VotingClassifier(estimators=[('LR',lr),('NB',NB),('SGD',sgd_clf),('DT',tree_clf),('svc',svm)],\n",
    "                        voting='hard',weights=[1,1,1,1,1])\n",
    "eAlg.fit(X_RUS, y_RUS)\n",
    "y_pred_class_vsRUS = eAlg.predict(X_test_dtm)\n",
    "print(classification_report(y_test, y_pred_class_vsRUS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fpr, tpr, thresholds = roc_curve(y_test, y_pred_class_lrRUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test['predit_lr']=y_pred_class_lr\n",
    "#test['predit_lrROS']=y_pred_class_lrROS\n",
    "#test['predit_lrRUS']=y_pred_class_lrRUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "#test.to_csv(\"test1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
